# ─────────────────────────────────────────────────────────────────────────────
# NeuralClaw — Configuration (Ollama Local Mode)
# ─────────────────────────────────────────────────────────────────────────────

# REQUIRED for loader
default_llm_provider: "ollama"
default_llm_model: "qwen2.5:3b"

agent:
  name: "NeuralClaw"
  version: "1.0.0"
  max_iterations_per_turn: 10
  max_turn_timeout_seconds: 300
  default_trust_level: "low"

llm:
  default_provider: "ollama"
  default_model: "qwen2.5:3b"
  temperature: 0.4
  max_tokens: 4096

  providers:
    ollama:
      base_url: "http://localhost:11434"
    openai:
      base_url:
    anthropic: {}

memory:
  chroma_persist_dir: "./data/chroma"
  sqlite_path: "./data/sqlite/episodes.db"
  embedding_model: "qwen2.5:3b"
  max_short_term_turns: 20
  relevance_threshold: 0.85

tools:
  browser:
    headless: true
    user_agent: "Mozilla/5.0 (compatible; NeuralClaw/1.0)"
    timeout_ms: 15000

  terminal:
    working_dir: "./data/agent_files"
    default_timeout_seconds: 30
    docker_sandbox: false
    docker_image: "python:3.11-slim"
    whitelist_extra: []

  filesystem:
    allowed_paths:
      - "./data/agent_files"

safety:
  default_permission_level: "read"
  require_confirmation_for:
    - "HIGH"
    - "CRITICAL"

mcp:
  servers:
    blender:
      transport: stdio
      command: "uvx"
      args: ["blender-mcp"]
      enabled: false

telegram:
  authorized_user_ids: []

scheduler:
  timezone: "UTC"
  max_concurrent_tasks: 3

logging:
  level: "INFO"
  log_dir: "./data/logs"
  max_file_size_mb: 100
  backup_count: 5
  console_output: true
  json_format: true
